\documentclass[acmtocl]{acmtrans2m}

\title{Visualising Courtship Index from Videos of Drosophila}

\author{Michael Dewar, Tim Lukins and Douglas Armstrong}
\begin{abstract}
We present approach to the automated analysis and visualisation of courtship index (CI) in \emph{Drosophila} - usually defined as the percentage of time the male fruit fly spends displaying courtship behaviour over a fixed period. Using machine vision techniques we extract position and orientation features from video of courting flies. These features are then used in a classifier in order to determine the presence of courtship behaviour in each frame. Using this information we generate a set of visualisations which emphasises the time course of the behaviour. Hence, we arrive at a much richer interpretation of courtship index, one that highlights the dynamic aspects of \emph{Drosophila} courtship behaviour, exposing phenotypic information that the standard, manual assay would typically miss.
\end{abstract}

\category{H5.m}{Information interfaces and presentation}{Misc}

\begin{document}
	
	\maketitle

\section{Introduction}

Courtship index (CI) in \emph{Drosophila} is defined as the percentage of time spent by the male exhibiting any kind of courtship behaviour in a given period \cite{}. It is typically collected manually, by watching videos of courting flies and starting and stopping a stopwatch when courtship behaviour is observed. CI is a useful summary statistic, used to quantify a phenotypic change, and to correlate against a change in neurological structure \cite{}.

A trained individual is capable of recording courtship in four flies at a time, or in one fly at up to 4$\times$ real-time video playback. Even when the individual is totally accurate, this recording of courtship index involves two gross forms of information attenuation. The first is the attenuation of phenotypic information - compressing a large number of different behaviours into a single ``courtship'' behaviour (such as singing, chasing, dancing etc). The second is the attenuation of temporal information - compressing the time course of courtship behaviour into a single percentage. This paper aims to tackle temporal attenuation, using automatic machine vision and machine learning techniques to overcome the inherent limitations of manual analysis that necessitates such temporal attenuation.

The use of automated methods of analysis to overcome this attenuation has a set of additional benefits. The most striking of these benefits in practice is the reduction of labour - the methods reported below work faster than real time, removing the need to perform routine viewing of the collected videos and allowing the biologist to focus their time on analysing novel phenotypes that arise. Another benefit is consistency - the methods reported below will analyse the same video in the same way every time. This allows the comparisons of results across studies without dealing with (or guiltily ignoring) the problem that different individuals can analyse the same video quite differently. The final benefit is the ability to publish - the methods reported below will allow the publication of the classifier used to generate the results along with the collected video and feature data. This allows true sharing of results between individuals in a lab and between labs themselves, as the published video data can be re-analysed using both the reported classifier used by the authors of a paper, and the classifier that has been generated by the readers of a paper.

\section{Tracking}

Description of the machine vision component

\section{Extracting Courtship Index}

Description of the courtship classification component

\section{Visualisation}

Different visualisation options

\section{Classifying Courtship Dynamics}

Parmeterisation of the courtship index curves

\section{Performance}

Performance of the algorithm

\section{Conclusion}

Conclusion

\end{document}